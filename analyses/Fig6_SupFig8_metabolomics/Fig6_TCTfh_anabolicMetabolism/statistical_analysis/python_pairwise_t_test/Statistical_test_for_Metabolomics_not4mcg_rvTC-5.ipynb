{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# \n",
    "df = pd.read_csv(\"../../X0_raw_data/log2_tab.csv\")\n",
    "\n",
    "df.columns\n",
    "\n",
    "renamed_col = [x.split(\"-\")[0]+\"_\"+x.split(\" \")[1].split(\"_\")[0]+\n",
    " \"_\"+ x.split(\"-\")[1].split(\" \")[0] for x in df.columns if \"B6\" in x or \"TC\" in x]\n",
    "\n",
    "df.columns = [\"MID\"] + renamed_col + ['pool 1', 'pool 2'] \n",
    "\n",
    "df.columns\n",
    "\n",
    "df.to_csv(\"../../X0_raw_data/log2_tab_renamed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../X0_log2_transformed_log2FC/featab_simp_norm_annot_rm_TC-5_log2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"MID\"] + df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 by 2 comparisons\n",
    "# TC_Tfh vs B6_Tfh\n",
    "# TC_Tn vs B6_Tn\n",
    "# B6_Tfh vs B6_Tn\n",
    "# TC_Tfh vs TC_Tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set your Exp_id & condition\n",
    "Exp_id = \"\"\n",
    "cond = [\"TC.*Tfh\",\"B6.*Tfh\"] #\"B6.*Tfh\",\"B6.*Tn\",\"TC.*Tfh\",\"TC.*Tn\"\n",
    "cond_name = [x.replace(\".*\",\"_\") for x in cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1_TC.1_Tfh_010',\n",
       " 'C1_TC.2_Tfh_011',\n",
       " 'C1_TC.3_Tfh_012',\n",
       " 'C2_TC.1_Tfh_018',\n",
       " 'C2_TC.2_Tfh_019',\n",
       " 'C2_TC.3_Tfh_020',\n",
       " 'C2_TC.4_Tfh_021']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in df.columns if Exp_id in x and re.search(cond[0], x)] #using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(df.iloc[:,0])\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    try:\n",
    "        t,p = stats.ttest_ind( [float(x) for x in (df.loc[i,[x for x in df.columns if Exp_id in x and re.search(cond[0], x)]])], \n",
    "                              [float(x) for x in (df.loc[i,[x for x in df.columns if Exp_id in x and re.search(cond[1], x)]])] )\n",
    "        if math.isnan(p) is True:\n",
    "            res_df.loc[i,\"ttest_pval\" + Exp_id + \"_\" + \"vs\".join(cond_name) ] = 1\n",
    "            res_df.loc[i,\"ttest_tscore_\" + Exp_id  + \"_\" + \"vs\".join(cond_name)] = 0\n",
    "        else:\n",
    "            res_df.loc[i,\"ttest_pval\" + Exp_id + \"_\" + \"vs\".join(cond_name) ] = p\n",
    "            res_df.loc[i,\"ttest_tscore_\" + Exp_id  + \"_\" + \"vs\".join(cond_name)] = t\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        res_df.loc[i,\"ttest_pval\" + Exp_id + \"_\" + \"vs\".join(cond_name) ] = 1\n",
    "        res_df.loc[i,\"ttest_tscore_\" + Exp_id  + \"_\" + \"vs\".join(cond_name)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(\"ttest4\" + Exp_id + \"_\" + \"vs\".join(cond_name) + \".txt\", sep='\\t', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge annot df\n",
    "* This step can be done after BH adjustment of p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['padj_on_all_ttest4_B6_TfhvsB6_Tn.txt',\n",
       " 'padj_on_all_ttest4_TC_TfhvsB6_Tfh.txt',\n",
       " 'padj_on_all_ttest4_TC_TfhvsTC_Tn.txt',\n",
       " 'padj_on_all_ttest4_TC_TnvsB6_Tn.txt']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the files you would like to merge\n",
    "file_l = [x for x in os.listdir() if \"padj_on_all\" in x and \".R\" not in x];file_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "m_df = []\n",
    "for item in file_l:\n",
    "    temp = pd.read_table(item)\n",
    "    if i ==0:\n",
    "        m_df = temp\n",
    "    else:\n",
    "        m_df = pd.merge(m_df,temp, on = \"MID\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_df.to_csv(\"merged_ttest_padj_on_annot.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all df\n",
    "* This step can be done after BH adjustment of p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['padj_on_all_ttest4_B6_TFHvsB6_TN.txt',\n",
       " 'padj_on_all_ttest4_TC_TFHvsB6_TFH.txt',\n",
       " 'padj_on_all_ttest4_TC_TFHvsTC_TN.txt',\n",
       " 'padj_on_all_ttest4_TC_TNvsB6_TN.txt']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the files you would like to merge\n",
    "file_l = [x for x in os.listdir() if \"padj_on_all\" in x and \".R\" not in x];file_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "m_df = []\n",
    "for item in file_l:\n",
    "    temp = pd.read_table(item)\n",
    "    if i ==0:\n",
    "        m_df = temp\n",
    "    else:\n",
    "        m_df = pd.merge(m_df,temp, on = \"MID\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df.to_csv(\"merged_ttest_padj_on_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal Wallis test\n",
    "    KW-test is said to have at least 5 measurements per group :\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html\n",
    "        scipy.stats.kruskal\n",
    "    U-Whiney test is said to have at least 20 measurements per group :\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\n",
    "        scipy.stats.mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KW-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set your Exp_id & condition\n",
    "Exp_id = \"\"\n",
    "cond = [\"PUF1\",\"cobA\"]\n",
    "\n",
    "res_df = df.iloc[:,0:3]\n",
    "try:\n",
    "    for i in range(df.shape[0]):\n",
    "        t,p = stats.kruskal( [float(x) for x in (df.loc[i,[x for x in df.columns if Exp_id in x and cond[0] in x]])], \n",
    "                             [float(x) for x in (df.loc[i,[x for x in df.columns if Exp_id in x and cond[1] in x]])],\n",
    "                             nan_policy = 'omit')\n",
    "        res_df.loc[i,\"htest_pval_\" + Exp_id + \"_\" + \"vs\".join(cond) ] = p\n",
    "        res_df.loc[i,\"htest_tscore_\" + Exp_id  + \"_\" + \"vs\".join(cond)] = t\n",
    "        if isinstance(t,str):\n",
    "            print(\"yes\")\n",
    "except Exception as e:\n",
    "    print(e)        \n",
    "    \n",
    "res_df[\"htest_pval_\" + Exp_id + \"_\" + \"vs\".join(cond)].replace(np.nan, 1.0 , inplace=True)\n",
    "res_df[\"htest_tscore_\" + Exp_id + \"_\" + \"vs\".join(cond)].replace(np.nan, 1.0 , inplace=True)\n",
    "\n",
    "    \n",
    "cols = res_df.columns.tolist()\n",
    "\n",
    "new_cols = cols[1:] + [cols[0]]\n",
    "new_cols\n",
    "\n",
    "res_df_new = res_df[new_cols]\n",
    "\n",
    "res_df_new.to_csv(\"htest4mcg_\" + Exp_id + \"_\" + \"vs\".join(cond) + \".txt\", sep='\\t', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Whiney test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All numbers are identical in mannwhitneyu\n"
     ]
    }
   ],
   "source": [
    "#Set your Exp_id & condition\n",
    "Exp_id = \"_6_\"\n",
    "cond = [\"PUF1\",\"cobA\"]\n",
    "\n",
    "res_df = df.iloc[:,0:3]\n",
    "try:\n",
    "    for i in range(df.shape[0]):\n",
    "        t,p = stats.mannwhitneyu( [float(x) for x in (df.loc[i,[x for x in df.columns if Exp_id in x and cond[0] in x]])], \n",
    "                                  [float(x) for x in (df.loc[i,[x for x in df.columns if Exp_id in x and cond[1] in x]])],\n",
    "                                  use_continuity=True, alternative='two-sided')\n",
    "        res_df.loc[i,\"utest_pval_\" + Exp_id + \"_\" + \"vs\".join(cond) ] = p\n",
    "        res_df.loc[i,\"utest_tscore_\" + Exp_id  + \"_\" + \"vs\".join(cond)] = t\n",
    "        if isinstance(t,str):\n",
    "            print(\"yes\")\n",
    "except Exception as e:\n",
    "    print(e)        \n",
    "    \n",
    "res_df[\"utest_pval_\" + Exp_id + \"_\" + \"vs\".join(cond)].replace(np.nan, 1.0 , inplace=True)\n",
    "res_df[\"utest_tscore_\" + Exp_id + \"_\" + \"vs\".join(cond)].replace(np.nan, 1.0 , inplace=True)\n",
    "\n",
    "    \n",
    "cols = res_df.columns.tolist()\n",
    "\n",
    "new_cols = cols[1:] + [cols[0]]\n",
    "new_cols\n",
    "\n",
    "res_df_new = res_df[new_cols]\n",
    "\n",
    "res_df_new.to_csv(\"utest4mcg_\" + Exp_id + \"_\" + \"vs\".join(cond) + \".txt\", sep='\\t', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
